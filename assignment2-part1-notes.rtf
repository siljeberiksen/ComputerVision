{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset0 AppleColorEmoji;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red252\green97\blue117;\red203\green203\blue203;
\red84\green164\blue243;\red136\green172\blue206;\red112\green158\blue255;\red73\green176\blue119;}
{\*\expandedcolortbl;;\cssrgb\c0\c1\c1;\cssrgb\c100000\c47843\c53333;\cssrgb\c83529\c83529\c83529;
\cssrgb\c39216\c70980\c96471;\cssrgb\c60000\c73333\c84314;\cssrgb\c50980\c69412\c100000;\cssrgb\c34118\c73333\c54118;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \expnd0\expndtw0\kerning0
24.05.2024\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97 \
Error Compilation:\
\
\pard\pardeftab720\partightenfactor0
\cf3 RuntimeError\cf4 : mat1 and mat2 shapes cannot be multiplied (196608x256 and 3x128)\
\pard\pardeftab720\partightenfactor0
\cf2 196608 is input tensor ot the Linear layer (batch size x input_features)\
\
3x128 is weight matrix of Linear layer (output features x input x features)\
\
solution: change the input_dim, adjust on the dataset structure.\
\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
\pard\pardeftab720\partightenfactor0
\cf3 ---------------------------------------------------------------------------\cf4 \
\cf3 RuntimeError\cf4                               Traceback (most recent call last)\
\pard\pardeftab720\partightenfactor0
\cf5 \ul \ulc5 <ipython-input-46-3f6dc677e72e>\cf4 \ulnone  in \cf6 <cell line: 3>\cf7 ()\cf4 \
\pard\pardeftab720\partightenfactor0
\cf8       1\cf4  epochs \cf7 =\cf4  \cf6 20\cf4 \
\cf8       2\cf4  \
\cf8 ----> 3\cf3  best_val_acc, best_params, best_epoch = train_loop(\
\cf8       4\cf4      model\cf7 ,\cf4 \
\cf8       5\cf4      train_dl\cf7 ,\cf4 \
\
\pard\pardeftab720\partightenfactor0

\f1 \cf4 \
\
6 frames\
\
\pard\pardeftab720\partightenfactor0

\f0 \cf5 \ul /usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\cf4 \ulnone  in \cf6 forward\cf7 (self, input)\cf4 \
\pard\pardeftab720\partightenfactor0
\cf8     114\cf4  \
\cf8     115\cf4      \cf8 def\cf4  forward\cf7 (\cf4 self\cf7 ,\cf4  input\cf7 :\cf4  Tensor\cf7 )\cf4  \cf7 ->\cf4  Tensor\cf7 :\cf4 \
\cf8 --> 116\cf3          \cf8 return\cf4  F\cf7 .\cf4 linear\cf7 (\cf4 input\cf7 ,\cf4  self\cf7 .\cf4 weight\cf7 ,\cf4  self\cf7 .\cf4 bias\cf7 )\cf4 \
\cf8     117\cf4  \
\cf8     118\cf4      \cf8 def\cf4  extra_repr\cf7 (\cf4 self\cf7 )\cf4  \cf7 ->\cf4  str\cf7 :\cf4 \
\
\cf3 RuntimeError\cf4 : mat1 and mat2 shapes cannot be multiplied (196608x256 and 196608x256)\
\
\pard\pardeftab720\partightenfactor0
\cf2 Another dimensions error - the weight matrixes\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
Update 24/05 12.25 \
the training loop works! previously I used 3 channel RGB images. After looking into the last lab (SVHN dataset) they used single channel. So, I preprocessed the data into single channel instead (just like the lab).\
\
The accuracy is awful, though.\
\
\
What to do next:\
- Adjust Model Architecture:\
	- adding more layers\
	- techniques like dropout\
- Adjust the Learning Rate\
- Adjust the Batch Size\
	- on batch size 20: 0.1 best acc\
	- on batch size 50: 0.06 best acc -> even worse\
	- on batch size 30: 0.04 best acc -> worse 
\f2 \uc0\u55357 \u56854 
\f0 \
\
\
}